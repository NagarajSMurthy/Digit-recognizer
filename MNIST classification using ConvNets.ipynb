{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install \"pillow<7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch \n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ratio = 0.2\n",
    "transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomAffine(degrees=10,scale=(1,1.5)),\n",
    "                                transforms.RandomRotation(15, fill=(0,)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))\n",
    "                               ])\n",
    "\n",
    "\n",
    "\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_ratio*num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# Data samplers for train and validation sets\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, sampler=train_sampler, batch_size=32, shuffle=False)\n",
    "validloader = torch.utils.data.DataLoader(trainset, sampler=valid_sampler, batch_size=32, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, label = dataiter.next()\n",
    "images = images.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,6))\n",
    "for idx in range(16):\n",
    "    ax = fig.add_subplot(2,20/2,idx+1,xticks=[],yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]),cmap='gray')\n",
    "    # .item() gets the value contained in a Tensor\n",
    "    ax.set_title(str(label[idx].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Label_list = ['0','1','2','3','4','5','6','7','8','9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0].squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "64*14*14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvMNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvMNIST, self).__init__()  # Indicates that the MNIST class inherits properties from nn.Module.\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,32,3,1,1)      # 28*28*1\n",
    "        self.conv2 = nn.Conv2d(32,64,3,1,1) \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2) # 14*14*32\n",
    "        self.fc2 = nn.Linear(64*14*14,1000)\n",
    "        self.fc3 = nn.Linear(1000,256)\n",
    "        self.fc4 = nn.Linear(256,10)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.dropout(F.relu(self.conv1(x)))\n",
    "        x = self.dropout(F.relu(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1,64*14*14)\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = F.log_softmax(self.fc4(x),dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ConvMNIST()\n",
    "criterion = nn.NLLLoss()\n",
    "optimiser = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_loss_min = np.inf\n",
    "accuracy_list = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    print('Starting epoch:',e)\n",
    "    batch_loss = 0\n",
    "    valid_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        output = model(images)\n",
    "        loss = criterion(output,labels)\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        batch_loss += loss.item()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images, labels in validloader:\n",
    "            output = model(images)\n",
    "            loss = criterion(output,labels)\n",
    "            valid_loss +=loss.item()\n",
    "            \n",
    "            probs = torch.exp(output)\n",
    "            _, classes = torch.topk(probs, k=1, dim=1)\n",
    "            equals = classes == labels.view(*classes.shape)\n",
    "            accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "            \n",
    "    train_losses.append(batch_loss/len(trainloader))\n",
    "    valid_losses.append(valid_loss/len(validloader))\n",
    "    print(f\"Training loss: {batch_loss/len(trainloader)}, Validation loss: {valid_loss/len(validloader)}\")\n",
    "    print(f\"Accuracy (Validation): {accuracy.item()*100}%\")\n",
    "    accuracy_list.append(accuracy.item())\n",
    "    if (valid_loss/len(validloader)) <= valid_loss_min:\n",
    "        print(f\"Validation loss decreased from {valid_loss_min} to {valid_loss/len(validloader)}. Saving the model\")\n",
    "        valid_loss_min = valid_loss/len(validloader)\n",
    "        torch.save(model,'mnist_model/model_'+str(e)+'_loss'+str(valid_loss/len(validloader))+'.pth')\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.plot(accuracy_list, label='Validation accuracy')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "for inputs, labels in testloader:\n",
    "    #inputs = inputs.view(inputs.shape[0],-1)\n",
    "    \n",
    "    output = model(inputs)\n",
    "    loss = criterion(output,labels)\n",
    "    \n",
    "    test_loss +=loss.item()\n",
    "            \n",
    "    probs = torch.exp(output)\n",
    "    _, classes = torch.topk(probs, k=1, dim=1)\n",
    "    equals = classes == labels.view(*classes.shape)\n",
    "    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "    for i in range(len(labels)):\n",
    "        label = labels.data[i]\n",
    "        class_correct[label] += equals[i].item()\n",
    "        class_total[label] += 1\n",
    "        \n",
    "test_loss = test_loss/len(testloader)\n",
    "print(f\"Test Loss: {test_loss}, Accuracy: {(accuracy/len(testloader))*100}%\")\n",
    "print(class_correct)\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing a single image\n",
    "data = iter(testloader)\n",
    "img, label = data.next()\n",
    "img = img[2].unsqueeze(dim=0)\n",
    "\n",
    "out = model(img)\n",
    "\n",
    "prob = torch.exp(out)\n",
    "value, index = torch.topk(prob, k=1,dim=1)\n",
    "\n",
    "plt.imshow(img.squeeze())\n",
    "print(f\"Predicted class {Label_list[index[0][0]]}\")\n",
    "print(label[2])\n",
    "print(index[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
